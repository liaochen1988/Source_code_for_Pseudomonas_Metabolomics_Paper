{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gapsplit(\n",
    "        model, n, max_tries=None,\n",
    "        primary='sequential', primary_tol=0.001,\n",
    "        secondary_frac=0.05,\n",
    "        fva=None,\n",
    "        min_range=1e-5,\n",
    "        enforce_range=True,\n",
    "        report_interval=0.1,\n",
    "        quiet=False):\n",
    "    \"\"\"Randomly sample a COBRA model.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model: cobra.Model\n",
    "        The model to sample. The model will not be modified during sampling.\n",
    "    n: integer\n",
    "        Number of samples to generate\n",
    "    max_tries: integer, optional, default=None\n",
    "        Sampling attempts that return infeasible or unbounded solutions are\n",
    "        discarded. Thus the total number of optimizations may exceed `n` for\n",
    "        difficult models. `max_tries` limits the total number of attempts. If\n",
    "        None (default), gapsplit will continue until `n` feasible samples are\n",
    "        found.\n",
    "    primary: str, optional, default='sequential'\n",
    "        Strategy for selection the primary target. Targets are chosen\n",
    "        sequentially ('sequential', default), randomly ('random'), or by always\n",
    "        targeting the variable with the largest relative gap ('max').\n",
    "    primary_tol: float, optional, default=0.001\n",
    "        The primary target is split by setting the upper and lower bounds to\n",
    "        the midway point of the max gap. The bounds are set to within +/-\n",
    "        `primary_tol` times the width of the gap to avoid infeasible solutions\n",
    "        due to numerical issues.\n",
    "    secondary_frac: float, optional, default=0.05\n",
    "        Fraction of model variables randomly chosen as secondary targets during\n",
    "        each iteration. Default is 0.05 (5% of reactions). If 0, no secondary\n",
    "        targeting is used; this may decrease coverage but improves runtime for\n",
    "        numerically difficult models.\n",
    "    fva: pandas.DataFrame, optional, default=None\n",
    "        gapsplit uses flux variability analysis (FVA) to find the feasible\n",
    "        ranges for each variable. The user can supply the output of a previous\n",
    "        `cobra.flux_analysis.flux_variability_analysis` run to avoid re-running\n",
    "        FVA. If None (default), gapsplit will run FVA.\n",
    "    min_range: float, optional, default=1e-5\n",
    "        Variables are targeted only if their feasible range is larger than\n",
    "        this value.\n",
    "    enforce_range: boolean, optional, default=True\n",
    "        If true (default), round solutions to fall within the feasible range.\n",
    "        This prevents small deviations outside the feasible range from causing\n",
    "        small decreases in coverage.\n",
    "    report_interval: float or int, optional, default=0.1\n",
    "        Show the coverage and gap statistics at this interval. If a number\n",
    "        between 0.0 and 1.0 is given, gapsplit reports when that fraction of\n",
    "        `n` samples is finished (i.e. if N=1000 and reportInterval=0.1, reports\n",
    "        are printed every 100 samples.) To turn off reporting, set to 0.\n",
    "    quiet: boolean, optional, default=True\n",
    "        Set to false to keep gapslit from printing status updates.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pandas.DataFrame\n",
    "        A data frame with rows = samples and columns = reactions. This is the\n",
    "        same format as the other cobrapy samplers.\n",
    "    \"\"\"\n",
    "    # output has rows = samples, columns = variables\n",
    "    # cobrapy returns a pandas DF\n",
    "\n",
    "    if quiet:\n",
    "        report = lambda s: None\n",
    "    else:\n",
    "        report = lambda s: print(s)\n",
    "\n",
    "    reactions = model.reactions\n",
    "\n",
    "    if fva is None:\n",
    "        report(\"Calculating feasible ranges using FVA.\")\n",
    "        fva = cobra.flux_analysis.flux_variability_analysis(\n",
    "                model, reactions, fraction_of_optimum=0.0)\n",
    "    else:\n",
    "        report(\"Using supplied FVA ranges.\")\n",
    "\n",
    "    if secondary_frac >= 1.0:\n",
    "        n_secondary = secondary_frac\n",
    "    else:\n",
    "        n_secondary = np.floor(secondary_frac * len(model.reactions)).astype(int)\n",
    "\n",
    "    # only split reactions with feasible range >= min_range\n",
    "    idxs = (fva.maximum - fva.minimum >= min_range).to_numpy().nonzero()[0]\n",
    "    weights = (1/(fva.maximum - fva.minimum)**2).to_numpy()\n",
    "\n",
    "    report(\"Targeting {}/{} unblocked primary variables.\".format(len(idxs), len(model.reactions)))\n",
    "    report(\"Targeting {} secondary variables.\".format(n_secondary))\n",
    "\n",
    "    report_header, report_format = _make_report_header(n)\n",
    "    report(\"\\n\" + report_header)\n",
    "    if report_interval < 1.0:\n",
    "        report_interval = np.floor(report_interval * n).astype(int)\n",
    "\n",
    "    samples = np.zeros((n, len(model.reactions)))\n",
    "    k = 0\n",
    "    infeasible_count = 0\n",
    "    if primary == 'sequential':\n",
    "        # primary_var will increment\n",
    "        primary_var = -1\n",
    "    try_ = 0\n",
    "    start_time = time.time()\n",
    "    while True:\n",
    "        if max_tries is not None and try_ >= max_tries:\n",
    "            break\n",
    "        try_ += 1\n",
    "        relative, target, width = _maxgap(samples[0:k,idxs], fva.iloc[idxs,:])\n",
    "        if primary == 'max':\n",
    "            primary_var = np.argmax(relative)\n",
    "        elif primary == 'random':\n",
    "            primary_var = np.random.choice(len(idxs), 1).astype(int)[0]\n",
    "        elif primary == 'sequential':\n",
    "            primary_var += 1\n",
    "            if primary_var >= len(idxs):\n",
    "                primary_var = 0\n",
    "\n",
    "        primary_target = target[primary_var]\n",
    "        primary_lb = primary_target - primary_tol*width[primary_var]\n",
    "        primary_ub = primary_target + primary_tol*width[primary_var]\n",
    "\n",
    "        secondary_vars = np.random.choice(len(idxs), n_secondary, replace=False)\n",
    "        secondary_targets = target[secondary_vars]\n",
    "        secondary_weights = weights[idxs[secondary_vars]]\n",
    "\n",
    "        new_sample = _generate_sample(\n",
    "            model, idxs[primary_var], primary_lb, primary_ub,\n",
    "            idxs[secondary_vars], secondary_targets, secondary_weights)\n",
    "        if new_sample is not None:\n",
    "            if enforce_range:\n",
    "                new_sample[new_sample > fva.maximum] = fva.maximum[new_sample > fva.maximum]\n",
    "                new_sample[new_sample < fva.minimum] = fva.minimum[new_sample < fva.minimum]\n",
    "\n",
    "            samples[k,:] = new_sample\n",
    "            k += 1\n",
    "            if k % report_interval == 0:\n",
    "                elapsed = time.time() - start_time\n",
    "                remaining = elapsed / k * (n - k)\n",
    "                report(report_format.format(\n",
    "                        i=k, n=n, cov=100*(1-np.mean(relative)),\n",
    "                        min=np.min(relative), med=np.median(relative),\n",
    "                        max=np.max(relative), ela=elapsed, rem=remaining,\n",
    "                        inf=infeasible_count))\n",
    "        else:\n",
    "            infeasible_count += 1\n",
    "\n",
    "        if k >= n: break\n",
    "\n",
    "    if k < n:\n",
    "        # max_tries reached; return fewer than n samples\n",
    "        samples = samples[:k,:]\n",
    "\n",
    "    return pd.DataFrame(data=samples,columns=fva.maximum.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _generate_sample(\n",
    "        model, primary_var, primary_lb, primary_ub,\n",
    "        secondary_vars=None, secondary_targets=None, secondary_weights=None):\n",
    "    \"\"\"Formulate a [MI]QP to find a single solution.\"\"\"\n",
    "    with model:\n",
    "        model.reactions[primary_var].lower_bound = primary_lb\n",
    "        model.reactions[primary_var].upper_bound = primary_ub\n",
    "\n",
    "        if secondary_vars is not None:\n",
    "            quad_exp = 0\n",
    "            for i, sec in enumerate(secondary_vars):\n",
    "                diff = model.problem.Variable('difference_{}'.format(sec))\n",
    "                cons = model.problem.Constraint(\n",
    "                    model.reactions[sec].flux_expression - diff,\n",
    "                    lb=secondary_targets[i], ub=secondary_targets[i])\n",
    "                model.add_cons_vars([diff, cons])\n",
    "                quad_exp += secondary_weights[i] * diff**2\n",
    "            quad_obj = model.problem.Objective(quad_exp, direction='min')\n",
    "            model.objective = quad_obj\n",
    "        else:\n",
    "            model.objective = model.problem.Objective(0)\n",
    "\n",
    "        try:\n",
    "            solution = model.optimize()\n",
    "        except:\n",
    "            return None\n",
    "        \n",
    "        if solution.status != 'optimal':\n",
    "            return None\n",
    "        \n",
    "        return solution.fluxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _maxgap(points, fva=None):\n",
    "    # points has rows = samples, columns = variables\n",
    "\n",
    "    # make a copy because we're going to sort the columns\n",
    "    points = points.copy()\n",
    "    if fva is not None:\n",
    "        points = np.vstack((fva.minimum, points, fva.maximum))\n",
    "    points.sort(0)\n",
    "\n",
    "    gaps = points[1:,:] - points[0:-1,:]\n",
    "    width = gaps.max(0)\n",
    "    loc = gaps.argmax(0)\n",
    "    left = np.zeros(width.size)\n",
    "    for i in range(width.size):\n",
    "        left[i] = points[loc[i],i]\n",
    "    relative = width / (points[-1,:] - points[0,:])\n",
    "    target = left + width/2\n",
    "\n",
    "    return relative, target, width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _make_report_header(maxN):\n",
    "    \"\"\"Return the header and format string for reporting coverage.\"\"\"\n",
    "    nw = len(str(maxN))\n",
    "    frac_width = 2*nw + 1  # width of 300/1000\n",
    "    frac_header = 'Sample'\n",
    "    frac_format = '{i:' + str(nw) + 'd}/{n:' + str(nw) + 'd}'\n",
    "    if frac_width < len(frac_header):\n",
    "        pad = ''.join([' ' for _ in range(len(frac_header) - frac_width)])\n",
    "        frac_format = pad + frac_format\n",
    "    elif len(frac_header) < frac_width:\n",
    "        pad = ''.join([' ' for _ in range(frac_width - len(frac_header))])\n",
    "        frac_header = pad + frac_header\n",
    "    hdr = frac_header + \"   Coverage   MinGap   Median   MaxGap     Elapsed     Remaining   Infeasible\"\n",
    "    fmt = frac_format + \"    {cov:6.2f}%   {min:6.4f}   {med:6.4f}   {max:6.4f}   {ela:9.2f}     {rem:9.2f}   {inf:10d}\"\n",
    "    return hdr, fmt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert a model to graph\n",
    "def convert_from_model_to_graph(model, name, fba, element_to_trace, cofactors):\n",
    "    \n",
    "    # reaction and metabolite number\n",
    "    num_mets = len(model.metabolites); \n",
    "    num_rxns = len(model.reactions);\n",
    "    \n",
    "    # creats a .net file\n",
    "    fileID = open(name, 'w');\n",
    "\n",
    "    # initialize arc number\n",
    "    num_arc = 0;\n",
    "\n",
    "    # write node id\n",
    "    print(\"number of nodes = %d\" % (num_mets))\n",
    "    fileID.write('*Vertices %d\\n' % num_mets)\n",
    "\n",
    "    global_id = {}\n",
    "    for i, met in enumerate(model.metabolites):\n",
    "        fileID.write(str(i+1) + ' \"' + met.id + '\"\\n')\n",
    "        # assign a global id for each metabolite\n",
    "        global_id[met.id] = i+1\n",
    "\n",
    "    # count total number of arcs\n",
    "    for i, rxn in enumerate(model.reactions):\n",
    "    \n",
    "        # exclude biomass reaction\n",
    "        biomassRxn = [rxn.id for rxn in model.reactions if 'biomass' in rxn.id]\n",
    "\n",
    "        # cleans reaction with \"objective\"\n",
    "        objRxn = [rxn.id for rxn in model.reactions if 'objective' in rxn.id]\n",
    "        if len(biomassRxn)==0 and len(objRxn)==0:\n",
    "            biomassRxn = False\n",
    "        else:\n",
    "            biomassRxn = True\n",
    "\n",
    "        if (fba[rxn.id] == 0 or biomassRxn):\n",
    "            # controls for active reactions\n",
    "            continue \n",
    "        else:\n",
    "            # get stoichiometric coefficients\n",
    "            metPos = [met.id for met in rxn.metabolites if rxn.get_coefficient(met.id)>0] # products\n",
    "            metNeg = [met.id for met in rxn.metabolites if rxn.get_coefficient(met.id)<0] # reactants\n",
    "\n",
    "            # cleans graph from demand and sink reactions\n",
    "            if len(metPos)==0 or len(metNeg)==0:\n",
    "                continue\n",
    "\n",
    "            for met_j in metNeg:\n",
    "                formula_j = model.metabolites.get_by_id(met_j).name.split('_')[-1]\n",
    "                for met_k in metPos:\n",
    "                    formula_k = model.metabolites.get_by_id(met_k).name.split('_')[-1]\n",
    "                    if element_to_trace in formula_j and element_to_trace in formula_k and met_j not in cofactors and met_k not in cofactors:\n",
    "                        num_arc = num_arc + 1\n",
    "\n",
    "\n",
    "    # write arc number\n",
    "    print('number of arcs = %d' % num_arc)\n",
    "    fileID.write('*Arcs %d\\n' % num_arc);\n",
    "\n",
    "    for i, rxn in enumerate(model.reactions):\n",
    "        biomassRxn = [rxn.id for rxn in model.reactions if 'biomass' in rxn.id]\n",
    "        objRxn = [rxn.id for rxn in model.reactions if 'objective' in rxn.id]\n",
    "\n",
    "        if len(biomassRxn)==0 and len(objRxn)==0:\n",
    "            biomassRxn = False\n",
    "        else:\n",
    "            biomassRxn = True\n",
    "\n",
    "        if (fba[rxn.id] == 0 or biomassRxn):\n",
    "            # controls for active reactions\n",
    "            continue \n",
    "        else:\n",
    "            # get stoichiometric coefficients\n",
    "            metPos = [met.id for met in rxn.metabolites if rxn.get_coefficient(met.id)>0] # products\n",
    "            metNeg = [met.id for met in rxn.metabolites if rxn.get_coefficient(met.id)<0] # reactants\n",
    "\n",
    "            if len(metPos)==0 or len(metNeg)==0:\n",
    "                continue\n",
    "\n",
    "            for met_j in metNeg:\n",
    "                formula_j = model.metabolites.get_by_id(met_j).name.split('_')[-1]\n",
    "                for met_k in metPos:\n",
    "                    formula_k = model.metabolites.get_by_id(met_k).name.split('_')[-1]\n",
    "                \n",
    "                    # take into account flux value and directionality\n",
    "                    if element_to_trace in formula_j and element_to_trace in formula_k and met_j not in cofactors and met_k not in cofactors:\n",
    "                        if fba[rxn.id] > 0:\n",
    "                            # write arcs in forward direction\n",
    "                            fileID.write(str(global_id[met_j])+' '+str(global_id[met_k])+' '+str(abs(fba[rxn.id]))+' id '+rxn.id+'\\n')\n",
    "                        else:\n",
    "                            # write arcs in reverse direction\n",
    "                            fileID.write(str(global_id[met_k])+' '+str(global_id[met_j])+' '+str(abs(fba[rxn.id]))+' id '+rxn.id+' \\n')\n",
    "                        num_arc = num_arc + 1\n",
    "                    \n",
    "    fileID.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_flux_through_given_metabolites(model,fluxsol,met2check,flux_thres):\n",
    "    pass_all = True\n",
    "    for index, met_id in enumerate(met2check):\n",
    "        pass_index = False\n",
    "        for rxn in model.metabolites.get_by_id(met_id).reactions:\n",
    "            if abs(fluxsol[rxn.id]) >= flux_thres:\n",
    "                pass_index = True\n",
    "                #print('met id = %s, flux = %2.2f'%(met_id,fluxsol[rxn.id]))\n",
    "                break\n",
    "        if not pass_index:\n",
    "            for rxn in model.metabolites.get_by_id(met_id).reactions:\n",
    "                print(fluxsol[rxn.id])\n",
    "            pass_all = False\n",
    "            break\n",
    "        \n",
    "    if pass_all:\n",
    "        print('success')\n",
    "    else:\n",
    "        print('fail for', met_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_logL_of_graph(filename):\n",
    "    M = nx.read_pajek(filename)\n",
    "\n",
    "    # combine fluxes among equivalent edges\n",
    "    G = nx.DiGraph()\n",
    "    for u,v,data in M.edges(data=True):\n",
    "        w = data['weight']\n",
    "        if G.has_edge(u,v):\n",
    "            G[u][v]['weight'] += w\n",
    "        else:\n",
    "            G.add_edge(u, v, weight=w)\n",
    "        \n",
    "    # compute logL of each edge (-log(normalized probability of influx * normalized probability of outflux))\n",
    "    logL = {}\n",
    "    for edge in G.edges():\n",
    "        node1, node2 =  edge\n",
    "    \n",
    "        node1_outflux = 0\n",
    "        #print(node1)\n",
    "        for e1 in G.out_edges(node1):\n",
    "            #print(e1)\n",
    "            node1_outflux += G.get_edge_data(*e1)['weight']\n",
    "        prob_out = G.get_edge_data(*edge)['weight']/node1_outflux\n",
    "        \n",
    "        node2_influx = 0\n",
    "        #print(node2)\n",
    "        for e2 in G.in_edges(node2):\n",
    "            #print(e2)\n",
    "            node2_influx += G.get_edge_data(*e2)['weight']\n",
    "        prob_in = G.get_edge_data(*edge)['weight']/node2_influx\n",
    "    \n",
    "        #print(prob_out, prob_in)\n",
    "        logL[edge] = -np.log(prob_out*prob_in)\n",
    "\n",
    "    nx.set_edge_attributes(G, logL, 'logL')    \n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_shortest_distance(network, met2check,verbose=False):\n",
    "    import networkx as nx\n",
    "    \n",
    "    num_mets = len(met2check)\n",
    "    shortest_distance = np.ones((num_mets,num_mets))*np.inf\n",
    "    for index1,met_id1 in enumerate(met2check):\n",
    "        for index2, met_id2 in enumerate(met2check):\n",
    "            if index2 < index1:\n",
    "                continue\n",
    "        \n",
    "            # met_id1 -> met_id2\n",
    "            if verbose:\n",
    "                print('\\nFrom %s to %s' % (met_id1, met_id2))\n",
    "            if nx.has_path(network, source=met_id1, target=met_id2):\n",
    "                spath_forward = nx.shortest_path(network, source=met_id1, target=met_id2, weight='logL')\n",
    "                sdist_forward = nx.dijkstra_path_length(network, source=met_id1, target=met_id2, weight='logL')\n",
    "                if verbose:\n",
    "                    print('shortest path (network distance = %2.2f): '%(sdist_forward), end='')\n",
    "                    for index3, node in enumerate(spath_forward):\n",
    "                        if index3 == len(spath_forward)-1:\n",
    "                            print(node)\n",
    "                        else:\n",
    "                            print(node,'->',end='')\n",
    "            else:\n",
    "                sdist_forward = np.inf\n",
    "                if verbose:\n",
    "                    print('no path found in metabolic network from %s to %s' % (met_id1, met_id2))\n",
    "            shortest_distance[index1][index2] = sdist_forward\n",
    "        \n",
    "            # met_id2 -> met_id1\n",
    "            if verbose:\n",
    "                print('From %s to %s' % (met_id2, met_id1))\n",
    "            if nx.has_path(network, source=met_id2, target=met_id1):\n",
    "                spath_reverse = nx.shortest_path(network, source=met_id2, target=met_id1, weight='logL')\n",
    "                sdist_reverse = nx.dijkstra_path_length(network, source=met_id2, target=met_id1, weight='logL')\n",
    "                if verbose:\n",
    "                    print('shortest path (network distance = %2.2f): '%(sdist_reverse), end='')\n",
    "                    for index3, node in enumerate(spath_reverse):\n",
    "                        if index3==len(spath_reverse)-1:\n",
    "                            print(node)\n",
    "                        else:\n",
    "                            print(node,'->',end='')\n",
    "            else:\n",
    "                sdist_reverse = np.inf\n",
    "                if verbose:\n",
    "                    print('no path found in metabolic network from %s to %s' % (met_id2, met_id1))         \n",
    "            shortest_distance[index2][index1] = sdist_reverse\n",
    "            \n",
    "    df_shortest_distance = pd.DataFrame(shortest_distance, index=met2check, columns=met2check)\n",
    "    return df_shortest_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_tidy_comparison_table(met2check, df_dist_data, df_dist_network):\n",
    "    res = []\n",
    "    for index1,met_id1 in enumerate(met2check):\n",
    "        for index2, met_id2 in enumerate(met2check):\n",
    "            if index2 < index1:\n",
    "                continue\n",
    "            else:\n",
    "                res.append([met_id1,\n",
    "                            met_id2,\n",
    "                            df_dist_data.loc[met_id1,met_id2],\n",
    "                            df_dist_network.loc[met_id1,met_id2],\n",
    "                            df_dist_network.loc[met_id2,met_id1],\n",
    "                            min(df_dist_network.loc[met_id1,met_id2],df_dist_network.loc[met_id2,met_id1])])\n",
    "            \n",
    "    df_dist_tidy = pd.DataFrame(res,columns=['met_id_1',\n",
    "                                             'met_id_2',\n",
    "                                             'data_dist',\n",
    "                                             'network_dist_forward',\n",
    "                                             'network_dist_reverse',\n",
    "                                             'network_dist_min'])\n",
    "    df_dist_tidy = df_dist_tidy[~np.isinf(df_dist_tidy.network_dist_min)]\n",
    "    return df_dist_tidy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
